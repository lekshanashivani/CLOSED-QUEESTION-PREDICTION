KNN:
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifierfrom sklearn.pipeline import make_pipeline
from sklearn import metrics from bs4 import BeautifulSoupimport joblib
import matplotlib.pyplot as plt import seaborn as sns
df = pd.read_csv('train.csv')
# Define a function to remove HTML tags from the 'Body' columndef remove_html_tags(text):
soup = BeautifulSoup(text, 'html.parser')return soup.get_text()
df['Body'] = df['Body'].apply(remove_html_tags)
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Y'], test_size=0.2, random_state=42)
n_neighbors_value = 10
model = make_pipeline(TfidfVectorizer(), KNeighborsClassifier(n_neighbors=n_neighbors_value)) model.fit(X_train, y_train)
# Make predictions on the test set y_pred = model.predict(X_test)
# Evaluate the performance of the model
accuracy = metrics.accuracy_score(y_test, y_pred) print(f"Model Accuracy: {accuracy:.2f}")


NAIVE BAYES:
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
 
from sklearn.model_selection import train_test_splitfrom sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import make_pipeline
from sklearn import metrics from bs4 import BeautifulSoupimport joblib
import matplotlib.pyplot as plt import seaborn as sns

# Load your dataset
df = pd.read_csv('train.csv')

# Define a function to remove HTML tags from the 'Body' columndef remove_html_tags(text):
soup = BeautifulSoup(text, 'html.parser')return soup.get_text()

# Apply the function to the 'Body' column in your dataset df['Body'] = df['Body'].apply(remove_html_tags)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Y'],test_size=0.2, random_state=42)

# Create a pipeline with a TfidfVectorizer and a Multinomial NaiveBayesclassifie moel = make_pipeline(TfidfVectorizer(), MultinomialNB())
# Train the model model.fit(X_train, y_train)

# Make predictions on the test set y_pred = model.predict(X_test)

# Evaluate the performance of the model
accuracy = metrics.accuracy_score(y_test, y_pred) print(f"Model Accuracy: {accuracy:.2f}")
# Classification Report
classification_report_result = metrics.classification_report(y_test, y_pred) print("Classification Report:\n", classification_report_result)

# Confusion Matrix
confusion_matrix_result = metrics.confusion_matrix(y_test, y_pred)
 
print("Confusion Matrix:\n", confusion_matrix_result)

# Plot the Confusion Matrix plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Blues') plt.title('Confusion Matrix')
plt.xlabel('Predicted') plt.ylabel('Actual') plt.show()

# Save the trained model to a file joblib.dump(model, 'naive_bayes_model.pkl')

RANDOM FOREST:

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizerfm sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier # ImportRandomForestClassifier from sklearn.pipeline import make_pipelinefrom
sklearn import metrics
from bs4 import BeautifulSoup import joblib
import matplotlib.pyplot as plt import seaborn as sns

# Load your dataset
df = pd.read_csv('train.csv')

# Define a function to remove HTML tags from the 'Body' columndef remove_html_tags(text):
soup = BeautifulSoup(text, 'html.parser')return soup.get_text()# Apply the function to the 'Body' column in your datasetdf['Body'] = df['Body'].apply(remove_html_tags)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Y'],test_size=0.2, random_state=42)

# Specify the number of estimators (you can adjust this value) n_estimators_value
= 1500 # Adjust the number of estimators as needed
 

# Classification Report
classification_report_result = metrics.classification_report(y_test, y_pred) print("Classification Report:\n", classification_report_result)

# Confusion Matrix
confusion_matrix_result = metrics.confusion_matrix(y_test, y_pred) print("Confusion Matrix:\n", confusion_matrix_result)

# Plot the Confusion Matrix plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_result, annot=True, fmt='d'cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1']) plt.title('Confusion Matrix')
plt.xlabel('Predicted') plt.ylabel('Actual') plt.show()
# Save the trained model to a file joblib.dump(model, 'random_forest_model.pkl')

FLASK CONNECTION:
from flask import Flask, render_template, requestfrom bs4 import BeautifulSoup
import joblib

app = Flask(	name	)

def remove_html_tags(text):
soup = BeautifulSoup(text, 'html.parser')return soup.get_text()
def predict_result(title, body):
# Preprocess the input data
body = remove_html_tags(body)

# Load the trained models from the files naive_bayes_model = joblib.load('naive_bayes_model.pkl')knn_model = joblib.load('knn_model.pkl')
random_forest_model = joblib.load('random_forest_model.pkl') #Load	the random forest model
 
# Make predictions on the input data
prediction_nb = naive_bayes_model.predict([body])[0] prediction_knn = knn_model.predict([body])[0] prediction_rf = random_forest_model.predict([body])[0]
#Makeprediction using the random forest model

# Simple majority voting
if prediction_nb == prediction_knn == prediction_rf: majority_vote = prediction_nb
else:
majority_vote = prediction_knn return majority_vote
@app.route('/', methods=['GET', 'POST'])def index(): if request.method == 'POST': title
= request.form['title'] body = request.form['body']
# Get the prediction
prediction = predict_result(title, body)

return render_template('index.html', prediction=prediction,title=title, body=body)

return render_template('index.html', prediction=None)if

		name	== ' main	': app.run(debug=True)
hybrid:

import tkinter as tk
from bs4 import BeautifulSoup import joblib
from sklearn.feature_extraction.text import TfidfVectorizer knn_model = joblib.load('knn_model.pkl') random_forest_model = joblib.load('random_forest_model.pkl')
#Load the random forest model
prediction_nb = naive_bayes_model.predict([body])[0] prediction_knn = knn_model.predict([body])[0]
prediction_rf = random_forest_model.predict([body])[0] # Makerdiction
 
using the random forest model

# Simple majority voting
if prediction_nb == prediction_knn == prediction_rf: majority_vote = prediction_nb
def on_predict_button_click():title
= entry_title.get()
body = text_body.get("1.0", "end-1c") # Get text from TkinterTextwidget # Get the prediction
prediction = predict_result(title, body) # Display the result
result_label.config(text=f"Predicted Result: {prediction}")

# Create the main Tkinter windowroot
= tk.Tk()
root.title("Text Classification Prediction") #Create Tkinter widgets
lael_title = tk.Label(root, text="Title:") etry_title = tk.Entry(root, width=50)
label_body = tk.Label(root, text="Body:") text_body = tk.Text(root, height=10, width=50)
button_predict = tk.Button(root, text="Predict", command=on_predict_button_click)
result_label = tk.Label(root, text="Predicted Result: ")# Place widgets on the window
label_title.grid(row=0, column=0, padx=10, pady=5, sticky="w")
entry_title.grid(row=0, column=1, padx=10, pady=5, columnspan=2, sticky="w")

lbel_body.grid(row=1, column=0, padx=10, pady=5, sticky="w") ext_body.grid(row=1, column=1, padx=10, pady=5, columnspan=2,sticky="w")

button_predict.grid(row=2, column=0, columnspan=3, pady=10) result_label.grid(row=3, column=0, columnspan=3, pady=10)
# Start the Tkinter event loop root.mainloop()
 
